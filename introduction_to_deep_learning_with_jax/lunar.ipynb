{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/machine_learning_novice/venv/lib/python3.10/site-packages/haiku/_src/data_structures.py:37: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  PyTreeDef = type(jax.tree_structure(None))\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jaxlib\n",
    "import optax\n",
    "import haiku as hk\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2', new_step_api=True)\n",
    "print(env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ACTIONS = env.action_space.n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we need\n",
    "\n",
    "- [x] Environment \n",
    "- [] Memory Buffer\n",
    "- [] DQN model\n",
    "- [] loss function\n",
    "- [] Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainConfig:\n",
    "    MEMORY_SIZE = 10000\n",
    "    BATCH_SIZE = 64\n",
    "    UPDATE_PARAMS_EVERY_N_STEPS = 4\n",
    "    TAU = 0.001\n",
    "    E_MIN = 0.01\n",
    "    E_DECAY = 0.995\n",
    "    N_EPISODES = 2000\n",
    "    MAX_N_STEPS_PER_EPISODE = 1000\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from typing import NamedTuple\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Experience:\n",
    "    state: jnp.ndarray\n",
    "    action: int\n",
    "    reward: float\n",
    "    next_state: jnp.ndarray\n",
    "    done: bool\n",
    "\n",
    "\n",
    "memory = deque(maxlen=TrainConfig.MEMORY_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we need\n",
    "\n",
    "- [x] Environment \n",
    "- [x] Memory Buffer\n",
    "- [] DQN model\n",
    "- [] loss function\n",
    "- [] Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "# @dataclasses.dataclass\n",
    "class TrainingState(NamedTuple):\n",
    "    params: hk.Params\n",
    "    target_params: hk.Params\n",
    "    eval_params: hk.Params\n",
    "    opt_state: optax.OptState\n",
    "\n",
    "# @dataclasses.dataclass\n",
    "class Batch(NamedTuple):\n",
    "    states: jnp.ndarray\n",
    "    actions: int\n",
    "    rewards: float\n",
    "    next_states: jnp.ndarray\n",
    "    dones: bool\n",
    "\n",
    "\n",
    "\n",
    "def network_fn(x: jnp.ndarray) -> jnp.ndarray:\n",
    "    model = hk.Sequential(\n",
    "        [\n",
    "            hk.Linear(64),jax.nn.relu,\n",
    "            hk.Linear(64), jax.nn.relu,\n",
    "            hk.Linear(NUM_ACTIONS),\n",
    "        ]\n",
    "\n",
    "    )\n",
    "    return model(x)\n",
    "\n",
    "network = hk.without_apply_rng(hk.transform(network_fn))\n",
    "target_network = hk.without_apply_rng(hk.transform(network_fn))\n",
    "optimiser = optax.adam(1e-3)\n",
    "# Initialise network and optimiser; note we draw an input to get shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.random as jrandom\n",
    "import random\n",
    "import numpy as np\n",
    "keygen = jrandom.PRNGKey(0)\n",
    "\n",
    "def get_random_batch(memory):\n",
    "    batch = random.sample(memory, k=TrainConfig.BATCH_SIZE)\n",
    "    return Batch(\n",
    "        states=jnp.array([e.state for e in batch]),\n",
    "        actions=jnp.array([e.action for e in batch]),\n",
    "        rewards=jnp.array([e.reward for e in batch]),\n",
    "        next_states=jnp.array([e.next_state for e in batch]),\n",
    "        dones=jnp.array([e.done for e in batch]),\n",
    "    )\n",
    "\n",
    "small_memory = deque(maxlen=1000)\n",
    "\n",
    "state = env.reset()\n",
    "action = env.action_space.sample()\n",
    "for _ in range(200):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, is_done, *_ = env.step(action)\n",
    "    experience = Experience(state, action, reward, next_state, is_done)\n",
    "    small_memory.append(experience)\n",
    "\n",
    "batch = get_random_batch(small_memory)\n",
    "\n",
    "batch.states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/machine_learning_novice/venv/lib/python3.10/site-packages/haiku/_src/data_structures.py:144: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  leaves, treedef = jax.tree_flatten(tree)\n",
      "/workspaces/machine_learning_novice/venv/lib/python3.10/site-packages/haiku/_src/data_structures.py:145: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  return jax.tree_unflatten(treedef, leaves)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "initial_params = network.init(\n",
    "    jax.random.PRNGKey(seed=0), batch.states)\n",
    "initial_opt_state = optimiser.init(initial_params)\n",
    "train_state = TrainingState(initial_params, initial_params, initial_params, initial_opt_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we need\n",
    "\n",
    "- [x] Environment \n",
    "- [x] Memory Buffer\n",
    "- [x] DQN model\n",
    "- [] loss function\n",
    "- [] Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss(params: hk.Params, batch: Batch) -> jnp.ndarray:\n",
    "params = train_state.params\n",
    "state_actions_values = network.apply(params, batch.next_states)\n",
    "max_state_actions_values = jnp.max(state_actions_values, axis=1)\n",
    "targets = batch.rewards + jnp.where(batch.dones, 0.0, max_state_actions_values)\n",
    "\n",
    "q_values = network.apply(params, batch.states)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q_value_for_action_taken = q_values[jnp.arange(q_values.shape[0]), batch.actions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2785838  0.16615024 0.14843863 0.02754669]\n",
      "2\n",
      "0.14843863\n"
     ]
    }
   ],
   "source": [
    "print(q_values[0])\n",
    "print(batch.actions[0])\n",
    "print(q_value_for_action_taken[0])\n",
    "assert q_value_for_action_taken[0] == q_values[0][batch.actions[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, target_params, batch):\n",
    "    q_values = network.apply(params, batch.states)\n",
    "    q_values_pred = q_values[jnp.arange(q_values.shape[0]), batch.actions]\n",
    "\n",
    "    q_values_next = target_network.apply(target_params, batch.next_states)\n",
    "    q_values_next_max = jnp.max(q_values_next, axis=1)\n",
    "\n",
    "    q_value_true = batch.rewards + jnp.where(batch.dones, 0.0, q_values_next_max)\n",
    "    return jnp.mean((q_values_pred - q_value_true) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update(train_state: TrainingState, batch: Batch) -> TrainingState:\n",
    "    \"\"\"Learning rule (stochastic gradient descent).\"\"\"\n",
    "    grads = jax.grad(loss)(train_state.params, train_state.target_params, batch)\n",
    "    updates, opt_state = optimiser.update(grads, train_state.opt_state)\n",
    "    params = optax.apply_updates(train_state.params, updates)\n",
    "\n",
    "    # Update target network.\n",
    "    # params * TAU + (1 - TAU) * new_params\n",
    "    # target_params = params * TrainConfig.TAU  + (1 - TrainConfig.TAU) * train_state.target_params\n",
    "    target_params = optax.incremental_update(params, train_state.target_params, TrainConfig.TAU)\n",
    "    \n",
    "    # Compute avg_params, the exponential moving average of the \"live\" params.\n",
    "    # We use this only for evaluation (cf. https://doi.org/10.1137/0330046).\n",
    "    eval_params = optax.incremental_update(\n",
    "        params, train_state.eval_params, step_size=0.001)\n",
    "    return TrainingState(params, target_params, eval_params, opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.24135946, 0.03655888, 0.07189564, 0.03146065],\n",
       "             [0.24135946, 0.03655888, 0.07189564, 0.03146065]],            dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state =env.reset()\n",
    "batch_state = jnp.array([state, state])\n",
    "network.apply(train_state.params, state)\n",
    "network.apply(train_state.params, batch_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_epsilon(epsilon, train_config: TrainConfig):\n",
    "    return max(train_config.E_MIN, train_config.E_DECAY*epsilon)\n",
    "\n",
    "def exploit_or_explore(q_value: jnp.ndarray, epsilon: float = 0.1) -> int:\n",
    "    \"\"\"Exploit or explore according to epsilon-greedy policy.\"\"\"\n",
    "    if random.random() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        return np.array(jnp.argmax(q_value))\n",
    "\n",
    "def is_update_params(n_steps_taken: int, train_config: TrainConfig) -> bool:\n",
    "    \"\"\"Update params every `update_params_every` steps.\"\"\"\n",
    "    return (n_steps_taken + 1) % train_config.UPDATE_PARAMS_EVERY_N_STEPS == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 28 | Total point average of the last 100 episodes: -157.51"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m total_reward \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(train_config\u001b[39m.\u001b[39mMAX_N_STEPS_PER_EPISODE):\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     q_value \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39;49mapply(train_state\u001b[39m.\u001b[39;49mparams, state)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     action \u001b[39m=\u001b[39m exploit_or_explore(q_value\u001b[39m=\u001b[39mq_value, epsilon\u001b[39m=\u001b[39mepsilon)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     next_state, reward, is_done, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m/workspaces/machine_learning_novice/venv/lib/python3.10/site-packages/haiku/_src/multi_transform.py:298\u001b[0m, in \u001b[0;36mwithout_apply_rng.<locals>.apply_fn\u001b[0;34m(params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_fn\u001b[39m(params, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    297\u001b[0m   check_rng_kwarg(kwargs)\n\u001b[0;32m--> 298\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39;49mapply(params, \u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/workspaces/machine_learning_novice/venv/lib/python3.10/site-packages/haiku/_src/transform.py:127\u001b[0m, in \u001b[0;36mwithout_state.<locals>.apply_fn\u001b[0;34m(params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mstate\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    121\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mHaiku transform adds three arguments (params, state, rng) to apply. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mIf the functions you are transforming use the same names you must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mpass them positionally (e.g. `f.apply(.., my_state)` and not by \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mname (e.g. `f.apply(.., state=my_state)`)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 127\u001b[0m out, state \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mapply(params, {}, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m state:\n\u001b[1;32m    129\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf your transformed function uses `hk.\u001b[39m\u001b[39m{\u001b[39m\u001b[39mget,set}_state` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39mthen use `hk.transform_with_state`.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/machine_learning_novice/venv/lib/python3.10/site-packages/haiku/_src/transform.py:354\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.apply_fn\u001b[0;34m(params, state, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mwith\u001b[39;00m base\u001b[39m.\u001b[39mnew_context(params\u001b[39m=\u001b[39mparams, state\u001b[39m=\u001b[39mstate, rng\u001b[39m=\u001b[39mrng) \u001b[39mas\u001b[39;00m ctx:\n\u001b[1;32m    353\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m     out \u001b[39m=\u001b[39m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    355\u001b[0m   \u001b[39mexcept\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    356\u001b[0m     \u001b[39mraise\u001b[39;00m jax\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;32m/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb Cell 22\u001b[0m in \u001b[0;36mnetwork_fn\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnetwork_fn\u001b[39m(x: jnp\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m jnp\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     model \u001b[39m=\u001b[39m hk\u001b[39m.\u001b[39;49mSequential(\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m         [\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m             hk\u001b[39m.\u001b[39;49mLinear(\u001b[39m64\u001b[39;49m),jax\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mrelu,\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m             hk\u001b[39m.\u001b[39;49mLinear(\u001b[39m64\u001b[39;49m), jax\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mrelu,\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m             hk\u001b[39m.\u001b[39;49mLinear(NUM_ACTIONS),\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m         ]\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsruinard-machine-learning-novice-w96jq4w7556cgq9r/workspaces/machine_learning_novice/introduction_to_deep_learning_with_jax/lunar.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model(x)\n",
      "File \u001b[0;32m/workspaces/machine_learning_novice/venv/lib/python3.10/site-packages/haiku/_src/module.py:125\u001b[0m, in \u001b[0;36mModuleMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m init(module, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m (config\u001b[39m.\u001b[39mget_config()\u001b[39m.\u001b[39mmodule_auto_repr \u001b[39mand\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     \u001b[39mgetattr\u001b[39m(module, \u001b[39m\"\u001b[39m\u001b[39mAUTO_REPR\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)):\n\u001b[0;32m--> 125\u001b[0m   module\u001b[39m.\u001b[39m_auto_repr \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mauto_repr(\u001b[39mcls\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m   module\u001b[39m.\u001b[39m_auto_repr \u001b[39m=\u001b[39m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m(module)\n",
      "File \u001b[0;32m/workspaces/machine_learning_novice/venv/lib/python3.10/site-packages/haiku/_src/utils.py:72\u001b[0m, in \u001b[0;36mauto_repr\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m# Keep used kwargs in the order they appear in argspec.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m arg_names\u001b[39m.\u001b[39mextend(n \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m argspec\u001b[39m.\u001b[39margs \u001b[39mif\u001b[39;00m n \u001b[39min\u001b[39;00m kwargs)\n\u001b[0;32m---> 72\u001b[0m arg_values \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49mgetcallargs(\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# pylint: disable=deprecated-method\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m# Extract default parameter values.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m defaults \u001b[39m=\u001b[39m argspec\u001b[39m.\u001b[39mdefaults \u001b[39mor\u001b[39;00m ()\n",
      "File \u001b[0;32m/opt/python/3.10.4/lib/python3.10/inspect.py:1498\u001b[0m, in \u001b[0;36mgetcallargs\u001b[0;34m(func, *positional, **named)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetcallargs\u001b[39m(func, \u001b[39m/\u001b[39m, \u001b[39m*\u001b[39mpositional, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnamed):\n\u001b[1;32m   1493\u001b[0m     \u001b[39m\"\"\"Get the mapping of arguments to values.\u001b[39;00m\n\u001b[1;32m   1494\u001b[0m \n\u001b[1;32m   1495\u001b[0m \u001b[39m    A dict is returned, with keys the function argument names (including the\u001b[39;00m\n\u001b[1;32m   1496\u001b[0m \u001b[39m    names of the * and ** arguments, if any), and values the respective bound\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m    values from 'positional' and 'named'.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1498\u001b[0m     spec \u001b[39m=\u001b[39m getfullargspec(func)\n\u001b[1;32m   1499\u001b[0m     args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, ann \u001b[39m=\u001b[39m spec\n\u001b[1;32m   1500\u001b[0m     f_name \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
      "File \u001b[0;32m/opt/python/3.10.4/lib/python3.10/inspect.py:1285\u001b[0m, in \u001b[0;36mgetfullargspec\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[39m\"\"\"Get the names and default values of a callable object's parameters.\u001b[39;00m\n\u001b[1;32m   1254\u001b[0m \n\u001b[1;32m   1255\u001b[0m \u001b[39mA tuple of seven things is returned:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[39m  - wrapper chains defined by __wrapped__ *not* unwrapped automatically\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1269\u001b[0m     \u001b[39m# Re: `skip_bound_arg=False`\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1282\u001b[0m     \u001b[39m# getfullargspec() historically ignored __wrapped__ attributes,\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m     \u001b[39m# so we ensure that remains the case in 3.3+\u001b[39;00m\n\u001b[0;32m-> 1285\u001b[0m     sig \u001b[39m=\u001b[39m _signature_from_callable(func,\n\u001b[1;32m   1286\u001b[0m                                    follow_wrapper_chains\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1287\u001b[0m                                    skip_bound_arg\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1288\u001b[0m                                    sigcls\u001b[39m=\u001b[39;49mSignature,\n\u001b[1;32m   1289\u001b[0m                                    eval_str\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1290\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# Most of the times 'signature' will raise ValueError.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# But, it can also raise AttributeError, and, maybe something\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[39m# else. So to be fully backwards compatible, we catch all\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[39m# possible exceptions here, and reraise a TypeError.\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39munsupported callable\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mex\u001b[39;00m\n",
      "File \u001b[0;32m/opt/python/3.10.4/lib/python3.10/inspect.py:2456\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2451\u001b[0m             \u001b[39mreturn\u001b[39;00m sig\u001b[39m.\u001b[39mreplace(parameters\u001b[39m=\u001b[39mnew_params)\n\u001b[1;32m   2453\u001b[0m \u001b[39mif\u001b[39;00m isfunction(obj) \u001b[39mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[1;32m   2454\u001b[0m     \u001b[39m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[1;32m   2455\u001b[0m     \u001b[39m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[0;32m-> 2456\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_function(sigcls, obj,\n\u001b[1;32m   2457\u001b[0m                                     skip_bound_arg\u001b[39m=\u001b[39;49mskip_bound_arg,\n\u001b[1;32m   2458\u001b[0m                                     \u001b[39mglobals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mglobals\u001b[39;49m, \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m, eval_str\u001b[39m=\u001b[39;49meval_str)\n\u001b[1;32m   2460\u001b[0m \u001b[39mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[1;32m   2461\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[1;32m   2462\u001b[0m                                    skip_bound_arg\u001b[39m=\u001b[39mskip_bound_arg)\n",
      "File \u001b[0;32m/opt/python/3.10.4/lib/python3.10/inspect.py:2321\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2319\u001b[0m kind \u001b[39m=\u001b[39m _POSITIONAL_ONLY \u001b[39mif\u001b[39;00m posonly_left \u001b[39melse\u001b[39;00m _POSITIONAL_OR_KEYWORD\n\u001b[1;32m   2320\u001b[0m annotation \u001b[39m=\u001b[39m annotations\u001b[39m.\u001b[39mget(name, _empty)\n\u001b[0;32m-> 2321\u001b[0m parameters\u001b[39m.\u001b[39mappend(Parameter(name, annotation\u001b[39m=\u001b[39;49mannotation,\n\u001b[1;32m   2322\u001b[0m                             kind\u001b[39m=\u001b[39;49mkind))\n\u001b[1;32m   2323\u001b[0m \u001b[39mif\u001b[39;00m posonly_left:\n\u001b[1;32m   2324\u001b[0m     posonly_left \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/python/3.10.4/lib/python3.10/inspect.py:2632\u001b[0m, in \u001b[0;36mParameter.__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2630\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, kind, \u001b[39m*\u001b[39m, default\u001b[39m=\u001b[39m_empty, annotation\u001b[39m=\u001b[39m_empty):\n\u001b[1;32m   2631\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kind \u001b[39m=\u001b[39m _ParameterKind(kind)\n\u001b[1;32m   2633\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m   2634\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalue \u001b[39m\u001b[39m{\u001b[39;00mkind\u001b[39m!r}\u001b[39;00m\u001b[39m is not a valid Parameter.kind\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/python/3.10.4/lib/python3.10/enum.py:385\u001b[0m, in \u001b[0;36mEnumMeta.__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39mEither returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[39m`type`, if set, will be mixed in as the first base class.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[39mif\u001b[39;00m names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# simple value lookup\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__new__\u001b[39;49m(\u001b[39mcls\u001b[39;49m, value)\n\u001b[1;32m    386\u001b[0m \u001b[39m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_create_(\n\u001b[1;32m    388\u001b[0m         value,\n\u001b[1;32m    389\u001b[0m         names,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         start\u001b[39m=\u001b[39mstart,\n\u001b[1;32m    394\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    \n",
    "total_reward_history = []\n",
    "moving_average_window_size = 100\n",
    "epsilon = 1.0\n",
    "train_config = TrainConfig()\n",
    "for episode in range(train_config.N_EPISODES):\n",
    "    state = env.reset()\n",
    "    total_reward = 0.0\n",
    "\n",
    "    for step in range(train_config.MAX_N_STEPS_PER_EPISODE):\n",
    "        q_value = network.apply(train_state.params, state)\n",
    "        action = exploit_or_explore(q_value=q_value, epsilon=epsilon)\n",
    "        \n",
    "        next_state, reward, is_done, *_ = env.step(action)\n",
    "        experience = Experience(state, action, reward, next_state, is_done)\n",
    "        memory.append(experience)\n",
    "        if len(memory) < TrainConfig.MEMORY_SIZE:\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            if is_done:\n",
    "                break\n",
    "            continue\n",
    "\n",
    "        if is_update_params(step, train_config=train_config):\n",
    "            batch =get_random_batch(memory)\n",
    "            train_state = update(train_state, batch)\n",
    "\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        if is_done:\n",
    "            break\n",
    "\n",
    "    total_reward_history.append(total_reward)\n",
    "    mean_total_reward_in_window = np.mean(total_reward_history[-moving_average_window_size:])\n",
    "    epsilon = update_epsilon(epsilon, train_config)\n",
    "\n",
    "\n",
    "    print(f\"\\rEpisode {episode+1} | Total point average of the last {moving_average_window_size} episodes: {mean_total_reward_in_window:.2f}\", end=\"\")\n",
    "\n",
    "    if (episode+1) % moving_average_window_size == 0:\n",
    "        print(f\"\\rEpisode {episode+1} | Total point average of the last {moving_average_window_size} episodes: {mean_total_reward_in_window:.2f}\")\n",
    "\n",
    "    # We will consider that the environment is solved if we get an\n",
    "    # average of 200 points in the last 100 episodes.\n",
    "    if mean_total_reward_in_window >= 200.0:\n",
    "        print(f\"\\n\\nEnvironment solved in {episode+1} episodes!\")\n",
    "        # q_network.save('lunar_lander_model.h5')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669],\n",
       "              [0.2785838 , 0.16615024, 0.14843863, 0.02754669]],            dtype=float32),\n",
       " 0,\n",
       " 0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_values, action, np.asarray([action])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt \n",
    "# import time\n",
    "# done = False\n",
    "# state = env.reset()\n",
    "# frame = env.render(mode=\"rgb_array\")\n",
    "# for _ in range(100):    \n",
    "#     q_values = network.apply(train_state.params, state)\n",
    "#     action = jnp.argmax(q_values)\n",
    "#     state, _, done, *_ = env.step(np.asarray([action])[0])\n",
    "#     env.render()\n",
    "#     if done:\n",
    "#         env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "import imageio\n",
    "import IPython\n",
    "\n",
    "def create_video(filename, env, train_state, fps=30):\n",
    "    with imageio.get_writer(filename, fps=fps) as video:\n",
    "        done = False\n",
    "        state = env.reset()\n",
    "        frame = env.render(mode=\"rgb_array\")\n",
    "        video.append_data(frame)\n",
    "        while not done:    \n",
    "            q_values = network.apply(train_state.params, state)\n",
    "            action = jnp.argmax(q_values)\n",
    "            state, _, done, *_ = env.step(np.asarray([action])[0])\n",
    "            frame = env.render(mode=\"rgb_array\")\n",
    "            video.append_data(frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/machine_learning_novice/venv/lib/python3.10/site-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "[swscaler @ 0x5c2b5c0] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./lunar_lander.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "filename = \"./lunar_lander.mp4\"\n",
    "create_video(filename, env, train_state)\n",
    "Video(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/machine_learning_novice/venv/lib/python3.10/site-packages/haiku/_src/data_structures.py:144: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  leaves, treedef = jax.tree_flatten(tree)\n",
      "/workspaces/machine_learning_novice/venv/lib/python3.10/site-packages/haiku/_src/data_structures.py:145: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  return jax.tree_unflatten(treedef, leaves)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jax_module/linear/b:0',\n",
       " 'jax_module/linear/w:0',\n",
       " 'jax_module/linear_1/b:0',\n",
       " 'jax_module/linear_1/w:0',\n",
       " 'jax_module/linear_2/b:0',\n",
       " 'jax_module/linear_2/w:0']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tree\n",
    "from jax.experimental import jax2tf\n",
    "import sonnet as snt\n",
    "\n",
    "\n",
    "def network_fn(x: jnp.ndarray) -> jnp.ndarray:\n",
    "    model = hk.Sequential(\n",
    "        [\n",
    "            hk.Linear(64),jax.nn.relu,\n",
    "            hk.Linear(64), jax.nn.relu,\n",
    "            hk.Linear(4),\n",
    "        ]\n",
    "\n",
    "    )\n",
    "    return model(x)\n",
    "\n",
    "\n",
    "\n",
    "def create_variable(path, value):\n",
    "  name = '/'.join(map(str, path)).replace('~', '_')\n",
    "  return tf.Variable(value, name=name)\n",
    "\n",
    "polymorphic_state_shape = jax2tf.shape_poly.PolyShape(\n",
    "  \"None, 8\"\n",
    ")\n",
    "\n",
    "class JaxModule(snt.Module):\n",
    "  def __init__(self, params, apply_fn, name=None):\n",
    "    super().__init__(name=name)\n",
    "    self._params = tree.map_structure_with_path(create_variable, params)\n",
    "    self._apply = jax2tf.convert(lambda p, x: apply_fn(p, x), polymorphic_shapes=[None, \"b, 8\"])\n",
    "    self._apply = tf.autograph.experimental.do_not_convert(self._apply)\n",
    "\n",
    "  def __call__(self, inputs):\n",
    "    return self._apply(self._params, inputs)\n",
    "\n",
    "\n",
    "network = hk.without_apply_rng(hk.transform(network_fn))\n",
    "# network = hk.transform(network_fn)\n",
    "target_network = hk.without_apply_rng(hk.transform(network_fn))\n",
    "optimiser = optax.adam(1e-3)\n",
    "initial_params = network.init(\n",
    "    jax.random.PRNGKey(seed=0), batch.states)\n",
    "net = JaxModule(initial_params, network.apply)\n",
    "[v.name for v in net.trainable_variables]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([ 0.36484796, -0.00536182,  0.11019011,  0.01452891], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.apply(initial_params, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function(autograph=False, input_signature=[tf.TensorSpec([None, 8])])\n",
    "def forward(x):\n",
    "  return net(x)\n",
    "\n",
    "to_save = tf.Module()\n",
    "to_save.forward = forward\n",
    "to_save.params = list(net.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/machine_learning_novice/venv/lib/python3.10/site-packages/haiku/_src/data_structures.py:144: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
      "  leaves, treedef = jax.tree_flatten(tree)\n",
      "/workspaces/machine_learning_novice/venv/lib/python3.10/site-packages/haiku/_src/data_structures.py:145: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
      "  return jax.tree_unflatten(treedef, leaves)\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(to_save, \"./lunar_lander_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load(\"./lunar_lander_model/\")\n",
    "preds = loaded.forward(tf.ones([3, 8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0966568 ,  1.3465225 ,  0.3490748 , -0.35275942, -0.16664864,\n",
       "       -0.20712912,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "loaded = tf.saved_model.load(\"./lunar_lander_model/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fd19f60d2496e9c9e375be8bbaf07fa2fff2a8edc3dc6611f1c0b323d41b84b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
